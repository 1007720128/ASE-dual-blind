# CMA: Collaborative Microservice Autoscaling in Edge-Clouds via Graph-Attentive Modeling(Anonymous Submission)

This repository contains the **anonymous implementation** of a method proposed in our paper under review. It introduces **CMA**, a distributed autoscaling framework for microservice-based applications in edge-cloud environments. CMA addresses key challenges of dynamic dependency modeling, inter-node coordination, and policy generalization by integrating the following components:

- âš¡ **Dependency Attention**: Learns runtime service invocation patterns via graph attention, replacing static or manually defined call graphs.
- ğŸ”„ **Information Attention**: Dynamically filters and prioritizes cross-node signals for decentralized autoscaling policies, enhancing coordination and adaptability.
- ğŸ¤ **Collaborative Multi-Agent Framework**: Leverages multi-agent reinforcement learning (MARL) to enable scalable and generalizable decision-making across heterogeneous nodes.

> â— **Note:** Due to system-level integration requirements, the provided implementation may not be directly executable without an appropriate runtime environment (see below for details).

---

## ğŸ“ Directory Structure

```text
.
â”œâ”€â”€ runner.py               # Entry point for training and evaluation
â”œâ”€â”€ algos/
â”‚   â””â”€â”€ CMA/                # Core algorithm implementation (attention modules, MARL, etc.)
    â””â”€â”€ ...
â”œâ”€â”€ onpolicy/               # Utility functions and shared training components
```
---
## ğŸ”Œ Environment Integration

CMA is designed to be **environment-agnostic**, but requires access to a runtime-compatible environment for actual execution.

To run the CMA, users need to **provide the environment interface** to CMA, which includes runtime control and metric access.

The current codebase supports both:
- Real clusters (e.g., local K8s + Prometheus setup)
- Simulated environments
---

## ğŸ“Œ Notice

This repository is anonymized for double-blind review. While full execution requires a connected environment, the following have been provided:

- Complete algorithmic implementation
- Modular code for core functionality (`algos/CMA/`)
   - `algos/CMA/DependencyAtt` â€” implements **Dependency Attention**, which dynamically infers runtime service dependencies
   - `algos/CMA/TransformerConvNet` â€” implements **Information Attention**, which filters inter-server messages based on contextual relevance
  - `algos/CMA/GR_MAPPOPolicy` â€” **Distributed Collaborative Autoscaler** : implements the decentralized MARL-based autoscaling policy

We appreciate your understanding and welcome any questions for clarification.

---